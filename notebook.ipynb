{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c011234-9d96-4e17-8ba3-ff4e043e393d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9fc9f-f9d7-4155-9d70-384fa02f0f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 知識庫製作\n",
    "!python3 ingest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2126232-6e9d-4c16-b9e1-b56839dfd840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 問答\n",
    "!python3 model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92e3ec-ed57-4e6b-89b6-6028eb0ba459",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 知識庫製作\n",
    "\n",
    "# 01: Configure\n",
    "pdf_file='Medical_Chatbot.pdf'\n",
    "http_proxy='http://lgn304-v304:53128'\n",
    "PINECONE_API_KEY='20163887-a4fa-44e7-98d2-ab1eb38937f6'\n",
    "PINECONE_API_ENV='gcp-starter'\n",
    "index_name=\"cjz-medical\"\n",
    "\n",
    "# 02: Load LIBRARY\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone.core.client.configuration import Configuration as OpenApiConfiguration\n",
    "#from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "\n",
    "# 03: Locad PDF\n",
    "loader= PyPDFLoader(pdf_file)\n",
    "data=loader.load()\n",
    "\n",
    "# 04: Text splitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs=text_splitter.split_documents(data)\n",
    "\n",
    "# 05: Embeddings 模型 384維度 \n",
    "embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# 06: 儲存至 pinecone 向量資料庫\n",
    "openapi_config = OpenApiConfiguration.get_default_copy()\n",
    "openapi_config.proxy = http_proxy\n",
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_API_ENV,openapi_config=openapi_config)\n",
    "docsearch = Pinecone.from_texts([t.page_content for t in docs], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904e29e-9e48-431a-b3a0-9cea91d543e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 問答\n",
    "\n",
    "# 01: Configure\n",
    "http_proxy='http://lgn304-v304:53128'\n",
    "PINECONE_API_KEY='20163887-a4fa-44e7-98d2-ab1eb38937f6'\n",
    "PINECONE_API_ENV='gcp-starter'\n",
    "index_name=\"cjz-medical\"\n",
    "Embeddings_ID=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "MODEL_ID=\"/work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# 02: Load LIBRARY\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from pinecone.core.client.configuration import Configuration as OpenApiConfiguration\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import pinecone\n",
    "\n",
    "# 03: Embeddings 模型 384維度 \n",
    "embeddings=HuggingFaceEmbeddings(model_name=Embeddings_ID)\n",
    "\n",
    "# 04: LLM模型\n",
    "tokenizer=AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "pipeline=transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=MODEL_ID,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    max_length=1024,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "llm=HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature':0})\n",
    "    \n",
    "# 05: 連線 pinecone 向量資料庫\n",
    "openapi_config = OpenApiConfiguration.get_default_copy()\n",
    "openapi_config.proxy = http_proxy\n",
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_API_ENV,openapi_config=openapi_config)\n",
    "\n",
    "# 06: 搜尋 pinecone 向量資料庫, 列出前三名\n",
    "docsearch=Pinecone.from_existing_index(index_name, embeddings)\n",
    "query = \"What are Allergies\"\n",
    "docs=docsearch.similarity_search(query, k=3)\n",
    "\n",
    "# 07. LLM彙整\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "result=chain.run(input_documents=docs, question=query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8d491-9508-4b0a-b861-e07265a5a5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Image_BIO_pytorch_2.0.1-cuda11.7-cudnn8-runtime",
   "language": "python",
   "name": "bio_pytorch_2.0.1-cuda11.7-cudnn8-runtime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
